{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1d3f5d",
   "metadata": {},
   "source": [
    "# Data Augmentations Visualized\n",
    "\n",
    "This notebook provides visualizations of the data augmentations used in the DeepFont-Torch project. Each augmentation is applied to a sample image, and the results are displayed for comparison.\n",
    "\n",
    "The main augmentation we focus on is the greyscale gradient overlay, which simulates lighting effects on font images. This augmentation is not well described in the original DeepFont paper, so we provide a detailed implementation and visualization here. We also demonstrate the real and synthetic image augmentation pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83941b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from deepfont.data.augmentations import (\n",
    "    augmentation_pipeline,\n",
    "    add_greyscale_gradient,\n",
    ")\n",
    "\n",
    "# Create assets directory\n",
    "assets_dir = Path(\"../assets\")\n",
    "assets_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7403f6ee",
   "metadata": {},
   "source": [
    "## Helper Functions and Loading Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f11ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for loading and displaying images\n",
    "def load_image(path):\n",
    "    \"\"\"Load an image and convert to numpy array.\"\"\"\n",
    "    img = Image.open(path).convert(\"L\")  # Convert to grayscale\n",
    "    return np.array(img, dtype=np.uint8)\n",
    "\n",
    "\n",
    "def display_images(images, titles, figsize=(15, 5), cmap=\"gray\"):\n",
    "    \"\"\"Display multiple images in a row.\"\"\"\n",
    "    n = len(images)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, img, title in zip(axes, images, titles):\n",
    "        ax.imshow(img, cmap=cmap, vmin=0, vmax=255)\n",
    "        ax.set_title(title, fontsize=12)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def display_grid(images, titles, cols=3, figsize=(15, 10), cmap=\"gray\"):\n",
    "    \"\"\"Display multiple images in a grid.\"\"\"\n",
    "    n = len(images)\n",
    "    rows = (n + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    axes = axes.flatten() if n > 1 else [axes]\n",
    "\n",
    "    for i, (img, title) in enumerate(zip(images, titles)):\n",
    "        axes[i].imshow(img, cmap=cmap, vmin=0, vmax=255)\n",
    "        axes[i].set_title(title, fontsize=10, wrap=True)\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for i in range(n, len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Load example images\n",
    "data_dir = Path.cwd().parent / \"data\"\n",
    "synthetic_img = load_image(data_dir / \"pretraining_examples\" / \"example_0_label_0.png\")\n",
    "real_img = load_image(data_dir / \"pretraining_examples\" / \"example_0_real.jpeg\")\n",
    "\n",
    "print(f\"Loaded synthetic image: {synthetic_img.shape}\")\n",
    "print(f\"Loaded real image: {real_img.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5590996",
   "metadata": {},
   "source": [
    "## Greyscale Gradient Overlay\n",
    "\n",
    "The gradient overlay simulates lighting effects by adding a linear gradient across the image. This helps the model become robust to varying lighting conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743c90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply gradient multiple times to show variation\n",
    "images = [synthetic_img]\n",
    "titles = [\"Original\"]\n",
    "\n",
    "for i in range(4):\n",
    "    augmented = add_greyscale_gradient(synthetic_img.copy())\n",
    "    images.append(augmented)\n",
    "    titles.append(f\"Gradient {i + 1}\")\n",
    "\n",
    "display_images(images, titles, figsize=(18, 4))\n",
    "\n",
    "save_path = assets_dir / \"gradient_examples.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a676fe6b",
   "metadata": {},
   "source": [
    "## Real and Synthetic Image Augmentation Pipelines\n",
    "\n",
    "The real image augmentation pipeline includes a series of transformations that are applied to real font images during training. The synthetic image augmentation pipeline includes transformations that are applied to synthetically generated font images. We will visualize the effects of these pipelines on sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6009035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentation pipeline to real image multiple times to show variation\n",
    "augmented_images = []\n",
    "augmented_titles = []\n",
    "for i in range(6):\n",
    "    augmented = augmentation_pipeline(real_img.copy(), image_type=\"real\", aug_prob=0.5)\n",
    "    augmented_images.append(augmented)\n",
    "    augmented_titles.append(f\"Augmentation {i + 1}\")\n",
    "print(\"Real Images with Augmentation Pipeline:\")\n",
    "display_grid(augmented_images, augmented_titles, cols=3, figsize=(8, 4))\n",
    "save_path = assets_dir / \"real_augmentation_examples.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Apply augmentation pipeline to synthetic image multiple times to show variation\n",
    "augmented_images = []\n",
    "augmented_titles = []\n",
    "for i in range(6):\n",
    "    augmented = augmentation_pipeline(synthetic_img.copy(), image_type=\"synthetic\", aug_prob=0.5)\n",
    "    augmented_images.append(augmented)\n",
    "    augmented_titles.append(f\"Augmentation {i + 1}\")\n",
    "print(\"Synthetic Images with Augmentation Pipeline:\")\n",
    "display_grid(augmented_images, augmented_titles, cols=3, figsize=(8, 4))\n",
    "save_path = assets_dir / \"synthetic_augmentation_examples.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba101d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
